a428636d4c82 ("crypto: arm64/ghash-ce - use frame_push/pop macros consistently")
11031c0d7d6e ("crypto: arm64/gcm-ce - implement 4 way interleave")
fe3b99b64909 ("crypto: arm64/ghash - switch to AES library")
e52b7023cdad ("crypto: arm64 - convert to use crypto_simd_usable()")
580e29517840 ("crypto: arm64/gcm-aes-ce - fix no-NEON fallback code")
8336bdf12a9e ("crypto: arm64/crct10dif - register PMULL variants as separate algos")
d72b9d4acd54 ("crypto: arm64/crct10dif - revert to C code for short inputs")
5a22b198cd52 ("crypto: arm64/ghash - register PMULL variants as separate algos")
cc7cf991e9eb ("crypto: arm64/chacha20 - add XChaCha20 support")
a00fa0c88774 ("crypto: arm64/nhpoly1305 - add NEON-accelerated NHPoly1305")
1ca1b917940c ("crypto: chacha20-generic - refactor to allow varying number of rounds")
de61d7ae5d37 ("crypto: chacha20-generic - add XChaCha20 support")
5e04542a0e07 ("crypto: chacha20-generic - don't unnecessarily use atomic walk")
dd333449d0fb ("crypto: chacha20-generic - add HChaCha20 library function")
8a5a79d5556b ("crypto: x86/chacha20 - Add a 4-block AVX2 variant")
a5dd97f86211 ("crypto: x86/chacha20 - Add a 2-block AVX2 variant")
9b17608f15b9 ("crypto: x86/chacha20 - Use larger block functions more aggressively")
c3b734dd325d ("crypto: x86/chacha20 - Support partial lengths in 8-block AVX2 variant")
db8e15a24957 ("crypto: x86/chacha20 - Support partial lengths in 4-block SSSE3 variant")
e4e72063d3c0 ("crypto: x86/chacha20 - Support partial lengths in 1-block SSSE3 variant")
