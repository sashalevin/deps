7aa54be29765 ("locking/qspinlock, x86: Provide liveness guarantee")
756b1df4c2c8 ("locking/qspinlock: Rework some comments")
53bf57fab732 ("locking/qspinlock: Re-order code")
81d3dc9a349b ("locking/qspinlock: Add stat tracking for pending vs. slowpath")
ae75d9089ff7 ("locking/qspinlock: Use try_cmpxchg() instead of cmpxchg() when locking")
626e5fbc1435 ("locking/qspinlock: Use smp_store_release() in queued_spin_unlock()")
f9c811fac48c ("locking/qspinlock: Use atomic_cond_read_acquire()")
c61da58d8a9b ("locking/qspinlock: Kill cmpxchg() loop when claiming lock from head of queue")
59fb586b4a07 ("locking/qspinlock: Remove unbounded cmpxchg() loop from locking slowpath")
b247be3fe89b ("locking/qspinlock/x86: Increase _Q_PENDING_LOOPS upper bound")
625e88be1f41 ("locking/qspinlock: Merge 'struct __qspinlock' into 'struct qspinlock'")
11752adb68a3 ("locking/pvqspinlock: Implement hybrid PV queued/unfair locks")
34d54f3d6917 ("locking/pvqspinlock: Relax cmpxchg's to improve performance on some architectures")
3cded4179481 ("x86/paravirt: Optimize native pv_lock_ops.vcpu_is_preempted()")
de7689cf8f38 ("x86/xen: Support the vCPU preemption check")
446f3dc8cc0a ("locking/core, x86/paravirt: Implement vcpu_is_preempted(cpu) for KVM and Xen guests")
cfd8983f03c7 ("x86, locking/spinlocks: Remove ticket (spin)lock implementation")
b193049375b0 ("locking/pv-qspinlock: Use cmpxchg_release() in __pv_queued_spin_unlock()")
64a5e3cb3080 ("locking/qspinlock: Improve readability")
1f03e8d29192 ("locking/barriers: Replace smp_cond_acquire() with smp_cond_load_acquire()")
ca50e426f96c ("locking/qspinlock: Use atomic_sub_return_release() in queued_spin_unlock()")
38460a2178d2 ("locking/csd_lock: Use smp_cond_acquire() in csd_lock_wait()")
b82e530290a0 ("locking/qspinlock: Move __ARCH_SPIN_LOCK_UNLOCKED to qspinlock_types.h")
32d62510f949 ("locking/pvqspinlock: Enable slowpath locking count tracking")
cb037fdad677 ("locking/qspinlock: Use smp_cond_acquire() in pending code")
eaff0e7003cc ("locking/pvqspinlock: Move lock stealing count tracking code into pv_queued_spin_steal_lock()")
cd0272fab785 ("locking/pvqspinlock: Queue node adaptive spinning")
1c4941fd53af ("locking/pvqspinlock: Allow limited lock stealing")
45e898b73562 ("locking/pvqspinlock: Collect slowpath lock statistics")
8643cda549ca ("sched/core, locking: Document Program-Order guarantees")
b3e0b1b6d841 ("locking, sched: Introduce smp_cond_acquire() and use it")
829cf31751aa ("Merge branch 'sched/urgent' into locking/core, to pick up scheduler fix we rely on")
